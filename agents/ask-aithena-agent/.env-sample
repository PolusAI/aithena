# Logging
AITHENA_LOG_LEVEL="INFO"
USE_LOGFIRE=false
LOGFIRE_SERVICE_NAME="ask-aithena-agent"
LOGFIRE_SERVICE_VERSION="1.0.0"
LOGFIRE_TOKEN="sk-1212"

# Network
HTTPX_TIMEOUT=30
RABBITMQ_URL="amqp://guest:guest@localhost:5672/"

# LiteLLM Configuration
LITELLM_URL="http://localhost:4000/v1"
LITELLM_API_KEY="sk-1212"

# Prompts
PROMPTS_DIR="./prompts"

# Models
RESPONDER_MODEL="gpt-4.1"
RESPONDER_MODEL_TEMPERATURE=0.3
TALKER_MODEL="gpt-4.1"
TALKER_MODEL_TEMPERATURE=0.3
SEMANTICS_MODEL="mistral-small3.2"
SEMANTICS_TEMPERATURE=0.2
SHIELD_MODEL="o4-mini"
SHIELD_TEMPERATURE=0.2
AEGIS_ORCHESTRATOR_MODEL="o4-mini"
AEGIS_ORCHESTRATOR_TEMPERATURE=0.2
AEGIS_REFEREE_MODEL="o3"
AEGIS_REFEREE_TEMPERATURE=0.3

# Embeddings & Vector Search
ARCTIC_HOST="localhost"
ARCTIC_PORT=8000
EMBEDDING_TABLE="openalex.abstract_embeddings_arctic"
SIMILARITY_N=10

# Optional Model Parameters
# RESPONDER_MODEL_FREQUENCY_PENALTY=
# RESPONDER_MODEL_LOGIT_BIAS=
# RESPONDER_MODEL_MAX_TOKENS=
# RESPONDER_MODEL_TOP_P=
# RESPONDER_MODEL_PRESENCE_PENALTY=
# RESPONDER_MODEL_SEED=
# TALKER_MODEL_FREQUENCY_PENALTY=
# TALKER_MODEL_LOGIT_BIAS=
# TALKER_MODEL_MAX_TOKENS=
# TALKER_MODEL_TOP_P=
# TALKER_MODEL_PRESENCE_PENALTY=
# TALKER_MODEL_SEED=
